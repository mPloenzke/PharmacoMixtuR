---
title: "Cross-study predictive accuracy"
author: "Matt Ploenzke"
date: "8/12/2019"
output: html_document
---

```{r}
library(readxl)
library(tidyverse)
library(caret)
library(randomForest)
library(mlbench)
library(PharmacoGx)
```

Load data and filter to drug.
```{r}
min_posterior_probability_sensitive <- .25
dataset_to_test_on <- 'GDSC'
use_all_features <- FALSE
use_known_drug_features <- FALSE
downsample_features <- TRUE
base_log_dir <- paste('cross_testset_', dataset_to_test_on, sep='')
dir.create(base_log_dir,showWarnings = FALSE)

posterior_t <- readRDS('~/Desktop/Concordance/tidyPharmaco/CCLE_GDSC_fit_p60/posterior.formatted.RDS')
#posterior_t <- readRDS('~/concordance/CCLE_GDSC_fit_p60/posterior.formatted.RDS')
all_drugs <- posterior_t %>% group_by(drug) %>% distinct(experiment) %>% filter(n()>1) %>% ungroup() %>% distinct(drug) %>% pull(drug)
broad_drugs <- c('17-AAG','paclitaxel','PD-0325901','AZD6244')
drug_for_biomarkers <- all_drugs[1]
log_dir <- file.path(base_log_dir,drug_for_biomarkers)
dir.create(log_dir,showWarnings = FALSE)
naive_cutoff <- ifelse(drug_for_biomarkers %in% broad_drugs,.4,.2)

posterior <- posterior_t %>%
  filter(drug==drug_for_biomarkers) %>%
  select(cell, experiment, cell_type, posterior_probability_sensitive)
datasets <- posterior %>% distinct(experiment) %>% pull()
gene_drug_asociations <- read_excel('~/Desktop/Concordance/PSets/gene_drug_asociations.xlsx', sheet = "mutation") %>%
#gene_drug_asociations <- read_excel('~/concordance/PSets/gene_drug_asociations.xlsx', sheet = "mutation") %>%
  as_tibble() %>%
  bind_rows(read_excel('~/Desktop/Concordance/PSets/gene_drug_asociations.xlsx', sheet = "copy_number_variation"),
            read_excel('~/Desktop/Concordance/PSets/gene_drug_asociations.xlsx', sheet = "expression")) %>%
  #bind_rows(read_excel('~/concordance/PSets/gene_drug_asociations.xlsx', sheet = "copy_number_variation"),
  #          read_excel('~/concordance/PSets/gene_drug_asociations.xlsx', sheet = "expression")) %>%
  mutate(type=case_when(type=='expression' ~ 'rna',
                        type=='copy_number_variation' ~ 'cnv',
                        TRUE ~ type)) %>%
  rename(drug=compound) %>%
  select(type, drug, gene, source)
if (use_known_drug_features) {
  gene_drug_asociations <- gene_drug_asociations %>% filter(drug==drug_for_biomarkers)
}
```

Set up X and Y data matrices.
```{r}
common.features <- c("rna","rna2","mutation","fusion","cnv")
for (dataset in datasets) {
  load(file.path('~/Desktop/Concordance/PSets',paste(dataset,'RData',sep='.')))
  #load(file.path('~/concordance/PSets',paste(dataset,'RData',sep='.')))
  eval(parse(text = paste('tempPset <- ',dataset,sep='')))
  common.features <- common.features[which(common.features %in% names(tempPset@molecularProfiles))]
  eval(parse(text=paste('rm(',dataset,',tempPset)',sep='')))
}

rez <- list()
for (dataset in datasets) {
  load(file.path('~/Desktop/Concordance/PSets',paste(dataset,'RData',sep='.')))
  #load(file.path('~/concordance/PSets',paste(dataset,'RData',sep='.')))
  eval(parse(text = paste('tempPset <- ',dataset,sep='')))
  y_new_temp <- summarizeSensitivityProfiles(tempPset, sensitivity.measure = 'auc_recomputed', summary.stat = 'median', verbose = FALSE) %>%
    as.data.frame() %>%
    rownames_to_column('drug') %>%
    as_tibble() %>% 
    filter(drug==drug_for_biomarkers) %>%
    gather(key='cell',value='value',-drug) %>%
    filter(!is.na(value)) %>%
    mutate(waterfall=PharmacoGx:::callingWaterfall(value,type='AUC')) %>%
    ungroup() %>% 
    rename(auc_recomputed=value) %>%
    mutate(naive=ifelse(auc_recomputed>.2,'sensitive','resistant')) %>%
    mutate(experiment = dataset)
  ii <- 1
  for (feat in common.features) {
    features <- gene_drug_asociations %>%
      filter(type==feat) %>%
      distinct(gene) %>% 
      pull()
    if (use_all_features) {
      idx <- 1:length(featureInfo(tempPset,feat)$Symbol)
    } else {
      if ('Symbol' %in% colnames(featureInfo(tempPset,feat))) {
        idx <- which(featureInfo(tempPset,feat)$Symbol %in% features)
      } else if ('gene_name' %in% colnames(featureInfo(tempPset,feat))) {
        idx <- which(featureInfo(tempPset,feat)$gene_name %in% features)
      } else {
        print(paste('Unknown column in PSet: ', dataset, sep=''))
        next()
      }
    }
    molfeatures <- fNames(tempPset, feat)[idx]
    if (length(molfeatures) > 0) {
      stat <- ifelse(feat=='mutation','and','median')
      x_new <- summarizeMolecularProfiles(tempPset, mDataType = feat, summary.stat = stat, verbose=TRUE) %>%
        Biobase::exprs() %>%
        as.data.frame() %>%
        rownames_to_column('gene') %>%
        as_tibble() %>%
        gather(cell, value, -gene) %>%
        filter(gene %in% molfeatures) %>%
        mutate(gene = paste(gene,feat,sep='_')) %>%
        spread(gene, value) %>% 
        na.omit() 
    } else {
      x_new <- tibble(cell='NA')
    }
    if (ii == 1) {
      joined <- x_new 
      ii <- ii+1
    } else {
      joined <- x_new %>% full_join(joined,by='cell')
    }
  }
  rez[[dataset]] <- joined %>% inner_join(y_new_temp, by='cell')
  eval(parse(text=paste('rm(',dataset,',tempPset, x_new, joined, y_new_temp)',sep='')))
}
rez <- do.call(bind_rows, rez)
for (feat in common.features) {
  rez <- rez %>% mutate_at(vars(contains(feat)),funs(as.numeric))
}

# filter columns with all NA in a single experiment
for (vvar in colnames(rez)) {
  max_na <- rez %>% 
    group_by(experiment) %>% 
    summarize(tt = mean(is.na(!!sym(vvar)))) %>%
    ungroup() %>%
    pull(tt) %>%
    max
  if (max_na == 1) {
    rez <- rez %>% select(-!!sym(vvar))
  }
}
if (downsample_features) {
  var.sds <- c()
  for (feat in common.features) { 
    var.sds <- c(var.sds, apply(rez %>% select(contains(feat)), 2, sd, na.rm=TRUE))
  }
  var.sds <- sort(var.sds,decreasing = TRUE)
  top.variable <- names(var.sds[1:min(length(var.sds),1000)])
  rez <- rez %>% select(cell, top.variable, drug, auc_recomputed, waterfall, naive, experiment)
}
rez <- rez %>%
  inner_join(posterior %>% distinct(),by=c('cell','experiment')) %>% 
  mutate(cell_type = case_when(posterior_probability_sensitive > min_posterior_probability_sensitive ~ 'sensitive',TRUE ~ 'resistant'))
for (feat in common.features) {
  rez <- rez %>% mutate_at(vars(contains(feat)),funs( if_else( is.na(.), mean(.,na.rm=TRUE), .)))
}
```

Define custom random forest caret method for classification.
```{r}
customRF <- list(type = "Classification", library = "randomForest", loop = NULL)
customRF$parameters <- data.frame(parameter = c("mtry", "ntree"), class = rep("numeric", 2), label = c("mtry", "ntree"))
customRF$grid <- function(x, y, len = NULL, search = "grid") {}
customRF$fit <- function(x, y, wts, param, lev, last, weights, classProbs, ...) {
  randomForest(x, y, mtry = param$mtry, ntree=param$ntree, ...)
}
customRF$predict <- function(modelFit, newdata, preProc = NULL, submodels = NULL) {predict(modelFit, newdata)}
customRF$prob <- function(modelFit, newdata, preProc = NULL, submodels = NULL) {predict(modelFit, newdata, type = "prob")}
customRF$sort <- function(x) {x[order(x[,1]),]}
customRF$levels <- function(x) {x$classes}
```

Define custom random forest caret method for regression.
```{r}
customRF2 <- list(type = "Regression", library = "randomForest", loop = NULL)
customRF2$parameters <- data.frame(parameter = c("mtry", "ntree"), class = rep("numeric", 2), label = c("mtry", "ntree"))
customRF2$grid <- function(x, y, len = NULL, search = "grid") {}
customRF2$fit <- function(x, y, wts, param, lev, last, weights, classProbs, ...) {
  randomForest(x, y, mtry = param$mtry, ntree=param$ntree, ...)
}
customRF2$predict <- function(modelFit, newdata, preProc = NULL, submodels = NULL) {predict(modelFit, newdata)}
customRF2$prob <- function(modelFit, newdata, preProc = NULL, submodels = NULL) {predict(modelFit, newdata, type = "prob")}
customRF2$sort <- function(x) {x[order(x[,1]),]}
customRF2$levels <- function(x) {x$classes}
```

Train models for varying binary outcome variables.
```{r}
metric <- "Accuracy"
set.seed(12345)
control <- trainControl(method="repeatedcv", number=10, repeats=3)
tunegrid <- expand.grid(.mtry=c(1:20), .ntree=c(10, 50, 100, 150))
all_acc <- tibble()
test_points <- rez %>% filter(experiment==dataset_to_test_on)
rez <- rez %>% filter(experiment!=dataset_to_test_on)
for (depVar in c('waterfall','naive','cell_type')) {
  x <- rez %>% 
    select(-drug, -cell, -experiment, -waterfall, -auc_recomputed, -naive, -cell_type, -posterior_probability_sensitive) %>% 
    select(matches(paste0(common.features,'$',collapse='|')))
  y <- rez %>% select(depVar)
  dataset <- y %>% 
    rename(Class=depVar) %>% 
    select(Class) %>% 
    bind_cols(x) %>% 
    na.omit() %>%
    mutate(Class = as.character(Class))
  if (depVar == 'waterfall') { 
    dataset <- dataset %>% 
      filter(Class!='intermediate')
  }
  print(nrow(dataset))
  custom <- train(Class~., data=dataset, method=customRF, metric=metric, tuneGrid=tunegrid, trControl=control)
  all_acc <- custom$results %>%
    as_tibble() %>% 
    mutate(outcome_variable=depVar, type='binary') %>%
    bind_rows(all_acc)
}
```

Same thing but continuous outcome variables.
```{r}
metric <- "RMSE"
control <- trainControl(method="repeatedcv", number=10, repeats=3)
tunegrid <- expand.grid(.mtry=c(1:20), .ntree=c(10, 50, 100, 150))
all_rmse <- tibble()
for (depVar in c('auc_recomputed','posterior_probability_sensitive')) {
  x <- rez %>% 
    select(-drug, -cell, -experiment, -waterfall, -auc_recomputed, -naive, -cell_type, -posterior_probability_sensitive) %>% 
    select(matches(paste0(common.features,'$',collapse='|')))
  y <- rez %>% select(depVar)
  dataset <- y %>% 
    rename(Class=depVar) %>% 
    select(Class) %>% 
    bind_cols(x) %>% 
    na.omit() 
  print(nrow(dataset))
  custom <- train(Class~., data=dataset, method=customRF2, metric=metric, tuneGrid=tunegrid, trControl=control)
  all_rmse <- custom$results %>%
    as_tibble() %>% 
    mutate(outcome_variable=depVar, type='continuous') %>%
    bind_rows(all_rmse)
}
```

Plot validation set accuracy results.
```{r}
p <- all_acc %>% 
  mutate(ntree2 = ntree) %>%
  mutate(ntree = paste('Number trees: ', ntree, sep='')) %>%
  mutate(ntree = reorder(ntree,ntree2)) %>%
  mutate(outcome_variable = case_when(outcome_variable == 'cell_type' ~ 'P(sensitive | AAC) > 0.5',
                                      outcome_variable == 'naive' ~ 'AAC > 0.2',
                                      outcome_variable == 'waterfall' ~ 'Waterfall method')) %>%
  ggplot(aes(x=mtry,y=Kappa, color=outcome_variable, group=outcome_variable)) + 
  geom_point(alpha=.75) +
  geom_line(alpha=.75) + 
  facet_wrap(vars(ntree), ncol=4) +
  theme_bw() + 
  scale_color_brewer(palette='Dark2') + 
  labs(x='Number features', color='', y='',title='Random Forest Model Performance for Different Binarization Methods', subtitle='10-fold cross validation Cohens kappa') + 
  theme(legend.position = 'top')
ggsave(file.path(log_dir,'CV_kappas.pdf'), p)
saveRDS(p,file.path(log_dir,'CV_kappas.RDS'))

p <- all_acc %>% 
  mutate(ntree2 = ntree) %>%
  mutate(ntree = paste('Number trees: ', ntree, sep='')) %>%
  mutate(ntree = reorder(ntree,ntree2)) %>%
  mutate(outcome_variable = case_when(outcome_variable == 'cell_type' ~ 'P(sensitive | AAC) > 0.5',
                                      outcome_variable == 'naive' ~ 'AAC > 0.2',
                                      outcome_variable == 'waterfall' ~ 'Waterfall method')) %>%
  ggplot(aes(x=mtry,y=Accuracy, color=outcome_variable, group=outcome_variable)) + 
  geom_point(alpha=.75) +
  geom_line(alpha=.75) + 
  geom_errorbar(aes(ymin=Accuracy-AccuracySD, ymax=Accuracy+AccuracySD), width=.2, position=position_dodge(0.05),alpha=.75) + 
  facet_wrap(vars(ntree), ncol=4) +
  theme_bw() + 
  scale_color_brewer(palette='Dark2') + 
  labs(x='Number features', color='', y='',title='Random Forest Model Performance for Different Binarization Methods', subtitle='10-fold cross validation accuracy (Mean +/- SD)') + 
  theme(legend.position = 'top')
ggsave(file.path(log_dir,'CV_accuracy.pdf'), p)
saveRDS(p,file.path(log_dir,'CV_accuracy.RDS'))
```

Plot validation set RMSE results.
```{r}
p <- all_rmse %>% 
  mutate(ntree2 = ntree) %>%
  mutate(ntree = paste('Number trees: ', ntree, sep='')) %>%
  mutate(ntree = reorder(ntree,ntree2)) %>%
  mutate(outcome_variable = case_when(outcome_variable == 'posterior_probability_sensitive' ~ 'P(sensitive | AAC)',
                                      outcome_variable == 'auc_recomputed' ~ 'AAC')) %>%
  ggplot(aes(x=mtry,y=Rsquared, color=outcome_variable, group=outcome_variable)) + 
  geom_point(alpha=.75) +
  geom_line(alpha=.75) + 
  facet_wrap(vars(ntree), ncol=4) +
  theme_bw() + 
  scale_color_brewer(palette='Dark2') + 
  labs(x='Number features', color='', y='',title='Random Forest Model Performance for Different Sensitivity Methods', subtitle='10-fold cross validation R-squared') + 
  theme(legend.position = 'top')
ggsave(file.path(log_dir,'Rsq.pdf'), p)
saveRDS(p,file.path(log_dir,'Rsq.RDS'))
```

Plot the relationship between three outcome measures.
```{r}
x <- rez %>% 
    select(-drug, -cell, -experiment, -waterfall, -auc_recomputed, -naive, -cell_type, -posterior_probability_sensitive) %>% 
    select(ends_with('mutation'), ends_with('rna'), ends_with('cnv'))
y <- rez %>% select(cell, experiment, auc_recomputed, waterfall, naive, posterior_probability_sensitive, cell_type) 
dataset <- y %>% 
  bind_cols(x) %>% 
  na.omit() %>% 
  select(cell, experiment, auc_recomputed, waterfall, naive, posterior_probability_sensitive, cell_type)
p <- dataset %>%
  ggplot(aes(x=auc_recomputed, y=posterior_probability_sensitive, color=waterfall)) + 
  geom_point() + 
  theme_bw() + 
  facet_grid(cols=vars(experiment)) +
  scale_color_brewer(palette='Dark2') + 
  geom_hline(aes(yintercept=min_posterior_probability_sensitive),lty=2) + 
  geom_vline(aes(xintercept=.2),lty=2)
ggsave(file.path(log_dir,'relationship_between_labels.pdf'), p)
saveRDS(p,file.path(log_dir,'relationship_between_labels.RDS'))
```

Fit best model for each outcome to compare features learned. 
```{r}
best_params <- all_acc %>% 
  group_by(outcome_variable) %>%
  filter(Accuracy==max(Accuracy)) %>%
  ungroup() %>%
  group_by(outcome_variable) %>%
  filter(row_number()==1) %>%
  select(mtry, ntree, outcome_variable)
best_params_rmse <- all_rmse %>% 
  group_by(outcome_variable) %>%
  filter(Rsquared==max(Rsquared)) %>%
  select(mtry, ntree, outcome_variable)
```

Start with the naive fit.
```{r}
x <- rez %>% 
    select(-drug, -cell, -experiment, -waterfall, -auc_recomputed, -naive, -cell_type, -posterior_probability_sensitive) %>% 
    select(matches(paste0(common.features,'$',collapse='|')))
y <- rez %>% select(cell, experiment, waterfall, naive, posterior_probability_sensitive, cell_type, auc_recomputed) 
dataset <- y %>% 
  bind_cols(x) %>% 
  na.omit() 

dataset_temp <- dataset %>% select(naive, matches(paste0(common.features,'$',collapse='|'))) %>% mutate(naive=as.factor(naive))
fit1 <- randomForest(naive~.,data=dataset_temp,
                     ntree=pull(filter(best_params,outcome_variable=='naive'),ntree),
                     mtry=pull(filter(best_params,outcome_variable=='naive'),mtry))

naive_imp <- importance(fit1) %>%
  as.data.frame() %>%
  rownames_to_column('feature') %>% 
  as_tibble() %>%
  mutate(outcome_variable = 'naive')

naive_preds <- dataset_temp %>%
  select(naive) %>% 
  mutate(Outcome = 'naive') %>%
  rename(Actual=naive) %>%
  bind_cols(dataset %>% mutate(strawman = as.factor(naive)) %>% select(cell, experiment, strawman)) %>%
  mutate(Predicted=fit1$predicted)

naive_diagnostics <- confusionMatrix(factor(naive_preds$Actual,levels=c('resistant','sensitive')), factor(naive_preds$Predicted,levels=c('resistant','sensitive')))
naive_strawman <- confusionMatrix(factor(naive_preds$strawman,levels=c('resistant','sensitive')), factor(naive_preds$Predicted,levels=c('resistant','sensitive')))
```

Get test set predictions for this measure.
```{r}
x_test <- test_points %>% 
    select(-drug, -cell, -experiment, -waterfall, -auc_recomputed, -naive, -cell_type, -posterior_probability_sensitive) %>% 
    select(matches(paste0(common.features,'$',collapse='|')))
y_test <- test_points %>% select(cell, experiment, waterfall, naive, posterior_probability_sensitive, cell_type, auc_recomputed)
dataset_test <- y_test %>% 
  bind_cols(x_test) %>% 
  na.omit() 
dataset_test_temp <- dataset_test %>% select(naive, matches(paste0(common.features,'$',collapse='|'))) %>% mutate(naive=as.factor(naive))
naive_test_preds <- dataset_test %>%
  select(naive) %>% 
  mutate(Outcome = 'naive', strawman=naive) %>%
  rename(Actual=naive) %>%
  bind_cols(dataset_test %>% select(cell, experiment)) %>%
  mutate(Predicted=predict(fit1,dataset_test_temp))

naive_test_diagnostics <- confusionMatrix(factor(naive_test_preds$Actual,levels=c('resistant','sensitive')), factor(naive_test_preds$Predicted,levels=c('resistant','sensitive')))
naive_test_strawman <- confusionMatrix(factor(naive_test_preds$strawman,levels=c('resistant','sensitive')), factor(naive_test_preds$Predicted,levels=c('resistant','sensitive')))
```

Next use the posterior probability of sensitive.
```{r}
dataset_temp <- dataset %>% select(cell_type, matches(paste0(common.features,'$',collapse='|'))) %>% mutate(cell_type=as.factor(cell_type))
fit1 <- randomForest(cell_type~.,data=dataset_temp,
                     ntree=pull(filter(best_params,outcome_variable=='cell_type'),ntree),
                     mtry=pull(filter(best_params,outcome_variable=='cell_type'),mtry))
posterior_imp <- importance(fit1) %>%
  as.data.frame() %>%
  rownames_to_column('feature') %>% 
  as_tibble() %>% 
  mutate(outcome_variable = 'posterior')

posterior_preds <- dataset_temp %>%
  select(cell_type) %>% 
  mutate(Outcome = 'posterior') %>%
  rename(Actual=cell_type) %>%
  bind_cols(dataset %>% mutate(strawman = as.factor(naive)) %>% select(cell, experiment, strawman)) %>%
  mutate(Predicted=fit1$predicted)

posterior_diagnostics <- confusionMatrix(factor(posterior_preds$Actual,levels=c('resistant','sensitive')), factor(posterior_preds$Predicted,levels=c('resistant','sensitive')))
posterior_strawman <- confusionMatrix(factor(posterior_preds$strawman,levels=c('resistant','sensitive')), factor(posterior_preds$Predicted,levels=c('resistant','sensitive')))
```

Get test set predictions for this measure.
```{r}
dataset_test_temp <- dataset_test %>% select(cell_type, matches(paste0(common.features,'$',collapse='|'))) %>% mutate(cell_type=as.factor(cell_type))
posterior_test_preds <- dataset_test %>%
  select(cell_type, naive) %>% 
  mutate(Outcome = 'posterior', strawman=naive) %>%
  select(-naive) %>%
  rename(Actual=cell_type) %>%
  bind_cols(dataset_test %>% select(cell, experiment)) %>%
  mutate(Predicted=predict(fit1,dataset_test_temp))

posterior_test_diagnostics <- confusionMatrix(factor(posterior_test_preds$Actual,levels=c('resistant','sensitive')), factor(posterior_test_preds$Predicted,levels=c('resistant','sensitive')))
posterior_test_strawman <- confusionMatrix(factor(posterior_test_preds$strawman,levels=c('resistant','sensitive')), factor(posterior_test_preds$Predicted,levels=c('resistant','sensitive')))
```

Next for the waterfall.
```{r}
dataset_temp <- dataset %>% select(waterfall, matches(paste0(common.features,'$',collapse='|'))) %>% 
  mutate(waterfall=as.character(waterfall)) %>%
  filter(waterfall != 'intermediate') %>%
  mutate(waterfall=as.factor(waterfall))
fit1 <- randomForest(waterfall~.,data=dataset_temp,
                     ntree=pull(filter(best_params,outcome_variable=='waterfall'),ntree),
                     mtry=pull(filter(best_params,outcome_variable=='waterfall'),mtry),)
waterfall_imp <- importance(fit1) %>%
  as.data.frame() %>%
  rownames_to_column('feature') %>% 
  as_tibble() %>% 
  mutate(outcome_variable = 'waterfall')

waterfall_preds <- dataset_temp %>%
  select(waterfall) %>% 
  mutate(Outcome = 'waterfall') %>%
  rename(Actual=waterfall) %>%
  bind_cols(dataset %>% filter(waterfall != 'intermediate') %>% mutate(strawman = as.factor(naive)) %>% select(cell, experiment, strawman)) %>%
  mutate(Predicted=fit1$predicted)

waterfall_diagnostics <- confusionMatrix(factor(waterfall_preds$Actual,levels=c('resistant','sensitive')), factor(waterfall_preds$Predicted,levels=c('resistant','sensitive')))
waterfall_strawman <- confusionMatrix(factor(waterfall_preds$strawman,levels=c('resistant','sensitive')), factor(waterfall_preds$Predicted,levels=c('resistant','sensitive')))
```

Get test set predictions for this measure.
```{r}
dataset_test_temp <- dataset_test %>% select(waterfall, matches(paste0(common.features,'$',collapse='|'))) %>% mutate(waterfall=as.factor(waterfall))
waterfall_test_preds <- dataset_test %>%
  select(waterfall,naive) %>% 
  mutate(Outcome = 'waterfall',strawman=naive) %>%
  select(-naive) %>%
  rename(Actual=waterfall) %>%
  bind_cols(dataset_test %>% select(cell, experiment)) %>%
  mutate(Predicted=predict(fit1,dataset_test_temp))

waterfall_test_preds2 <- waterfall_test_preds %>% filter(Actual!='intermediate') %>% mutate(Actual=as.factor(as.character(Actual)))
waterfall_test_diagnostics <- confusionMatrix(factor(waterfall_test_preds2$Actual,levels=c('resistant','sensitive')), factor(waterfall_test_preds2$Predicted,levels=c('resistant','sensitive')))
waterfall_test_strawman <- confusionMatrix(factor(waterfall_test_preds$strawman,levels=c('resistant','sensitive')), factor(waterfall_test_preds$Predicted,levels=c('resistant','sensitive')))
```

Now for the raw sensitivity measure.
```{r}
dataset_temp <- dataset %>% select(auc_recomputed, matches(paste0(common.features,'$',collapse='|')))
fit1 <- randomForest(auc_recomputed~.,data=dataset_temp,
                     ntree=pull(filter(best_params_rmse,outcome_variable=='auc_recomputed'),ntree),
                     mtry=pull(filter(best_params_rmse,outcome_variable=='auc_recomputed'),mtry),)
auc_imp <- importance(fit1) %>%
  as.data.frame() %>%
  rownames_to_column('feature') %>% 
  as_tibble() %>% 
  mutate(outcome_variable = 'auc_recomputed')

auc_preds <- dataset_temp %>%
  select(auc_recomputed) %>% 
  mutate(Outcome = 'auc_recomputed') %>%
  rename(Actual=auc_recomputed) %>%
  bind_cols(dataset %>% mutate(strawman = as.factor(naive)) %>% select(cell, experiment, strawman)) %>%
  mutate(Predicted=fit1$predicted) %>%
  mutate(strawman_predicted = case_when(Predicted >= naive_cutoff ~ 'sensitive', TRUE ~ 'resistant'))

auc_diagnostics <- confusionMatrix(factor(ifelse(auc_preds$Actual>naive_cutoff,'sensitive','resistant'),levels=c('resistant','sensitive')), factor(ifelse(auc_preds$Predicted>naive_cutoff,'sensitive','resistant'),levels=c('resistant','sensitive')))
auc_strawman <- confusionMatrix(factor(auc_preds$strawman,levels=c('resistant','sensitive')), factor(auc_preds$strawman_predicted,levels=c('resistant','sensitive')))

auc_mse <- mean((auc_preds$Actual - auc_preds$Predicted)^2)
auc_rsq <- cor(auc_preds$Actual,auc_preds$Predicted)
auc_strawman_mse <- mean((as.numeric(auc_preds$strawman=='sensitive') - auc_preds$Predicted)^2)
auc_strawman_rsq <-cor(as.numeric(auc_preds$strawman=='sensitive'), auc_preds$Predicted)
```

Get test set predictions for this measure.
```{r}
dataset_test_temp <- dataset_test %>% select(auc_recomputed, matches(paste0(common.features,'$',collapse='|')))
auc_test_preds <- dataset_test %>%
  select(auc_recomputed,naive) %>% 
  mutate(Outcome = 'auc_recomputed',strawman=naive) %>%
  select(-naive) %>%
  rename(Actual=auc_recomputed) %>%
  bind_cols(dataset_test %>% select(cell, experiment)) %>%
  mutate(Predicted=predict(fit1,dataset_test_temp)) %>%
  mutate(strawman_predicted = case_when(Predicted >= naive_cutoff ~ 'sensitive', TRUE ~ 'resistant'))

auc_test_diagnostics <- confusionMatrix(factor(ifelse(auc_test_preds$Actual>naive_cutoff,'sensitive','resistant'),levels=c('resistant','sensitive')), factor(ifelse(auc_test_preds$Predicted>naive_cutoff,'sensitive','resistant'),levels=c('resistant','sensitive')))
auc_test_strawman <- confusionMatrix(factor(auc_test_preds$strawman,levels=c('resistant','sensitive')),
                                     factor(auc_test_preds$strawman_predicted,levels=c('resistant','sensitive')))

auc_test_mse <- mean((auc_test_preds$Actual - auc_test_preds$Predicted)^2)
auc_test_rsq <- cor(auc_test_preds$Actual,auc_test_preds$Predicted)
auc_test_strawman_mse <- mean((as.numeric(auc_test_preds$strawman=='sensitive') - auc_test_preds$Predicted)^2)
auc_test_strawman_rsq <-cor(as.numeric(auc_test_preds$strawman=='sensitive'), auc_test_preds$Predicted)
```

Now for the posterior probability measure.
```{r}
dataset_temp <- dataset %>% select(posterior_probability_sensitive, matches(paste0(common.features,'$',collapse='|')))
fit1 <- randomForest(posterior_probability_sensitive~.,data=dataset_temp,
                     ntree=pull(filter(best_params_rmse,outcome_variable=='posterior_probability_sensitive'),ntree),
                     mtry=pull(filter(best_params_rmse,outcome_variable=='posterior_probability_sensitive'),mtry),)
probsensitive_imp <- importance(fit1) %>%
  as.data.frame() %>%
  rownames_to_column('feature') %>% 
  as_tibble() %>% 
  mutate(outcome_variable = 'posterior_probability_sensitive')

probsensitive_preds <- dataset_temp %>%
  select(posterior_probability_sensitive) %>% 
  mutate(Outcome = 'posterior_probability_sensitive') %>%
  rename(Actual=posterior_probability_sensitive) %>%
  bind_cols(dataset %>% mutate(strawman = as.factor(naive)) %>% select(cell, experiment, strawman)) %>%
  mutate(Predicted=fit1$predicted) %>%
  mutate(strawman_predicted = case_when(Predicted >= naive_cutoff ~ 'sensitive', TRUE ~ 'resistant'))

probsensitive_diagnostics <- confusionMatrix(factor(ifelse(probsensitive_preds$Actual>min_posterior_probability_sensitive,'sensitive','resistant'),levels=c('resistant','sensitive')),
                                             factor(ifelse(probsensitive_preds$Predicted>min_posterior_probability_sensitive,'sensitive','resistant'),levels=c('resistant','sensitive')))
probsensitive_strawman <- confusionMatrix(factor(probsensitive_preds$strawman,levels=c('resistant','sensitive')), 
                                          factor(probsensitive_preds$strawman_predicted,levels=c('resistant','sensitive')))

probsensitive_mse <- mean((probsensitive_preds$Actual - probsensitive_preds$Predicted)^2)
probsensitive_rsq <- cor(probsensitive_preds$Actual,probsensitive_preds$Predicted)
probsensitive_strawman_mse <- mean((as.numeric(probsensitive_preds$strawman=='sensitive') - probsensitive_preds$Predicted)^2)
probsensitive_strawman_rsq <-cor(as.numeric(probsensitive_preds$strawman=='sensitive'), probsensitive_preds$Predicted)
```

Get test set predictions for this measure.
```{r}
dataset_test_temp <- dataset_test %>% select(posterior_probability_sensitive, matches(paste0(common.features,'$',collapse='|')))
probsensitive_test_preds <- dataset_test %>%
  select(posterior_probability_sensitive,naive) %>% 
  mutate(Outcome = 'posterior_probability_sensitive',strawman=naive) %>%
  select(-naive) %>%
  rename(Actual=posterior_probability_sensitive) %>%
  bind_cols(dataset_test %>% select(cell, experiment)) %>%
  mutate(Predicted=predict(fit1,dataset_test_temp)) %>%
  mutate(strawman_predicted = case_when(Predicted >= naive_cutoff ~ 'sensitive', TRUE ~ 'resistant'))

probsensitive_test_diagnostics <- confusionMatrix(factor(ifelse(probsensitive_test_preds$Actual>min_posterior_probability_sensitive,'sensitive','resistant'),levels=c('resistant','sensitive')),
                                             factor(ifelse(probsensitive_test_preds$Predicted>min_posterior_probability_sensitive,'sensitive','resistant'),levels=c('resistant','sensitive')))
probsensitive_test_strawman <- confusionMatrix(factor(probsensitive_test_preds$strawman,levels=c('resistant','sensitive')), 
                                          factor(probsensitive_test_preds$strawman_predicted,levels=c('resistant','sensitive')))

probsensitive_test_mse <- mean((probsensitive_test_preds$Actual - probsensitive_test_preds$Predicted)^2)
probsensitive_test_rsq <- cor(probsensitive_test_preds$Actual,probsensitive_test_preds$Predicted)
probsensitive_test_strawman_mse <- mean((as.numeric(probsensitive_test_preds$strawman=='sensitive') - probsensitive_test_preds$Predicted)^2)
probsensitive_test_strawman_rsq <-cor(as.numeric(probsensitive_test_preds$strawman=='sensitive'), probsensitive_test_preds$Predicted)
```

Join all variable importance measures together.
```{r}
all.importance <- bind_rows(waterfall_imp, posterior_imp, naive_imp, auc_imp, probsensitive_imp)
```

Join all in-sample predictions.
```{r}
all.predictions <- naive_preds %>% 
  bind_rows(posterior_preds, waterfall_preds) %>%
  mutate(strawman_predicted = Predicted) %>%
  mutate(Actual = case_when(Actual=='sensitive' ~ 1, 
                            Actual=='resistant' ~ 0,
                            Actual=='intermediate' ~ 0.5),
         Predicted = case_when(Predicted=='sensitive' ~ 1, 
                               Predicted=='resistant' ~ 0)) %>%
  bind_rows(probsensitive_preds, auc_preds) %>%
  left_join(dataset %>% select(cell, experiment, auc_recomputed, posterior_probability_sensitive), by=c('cell','experiment'))
```

Same for test set predictions.
```{r}
all.test.predictions <- naive_test_preds %>% 
  bind_rows(posterior_test_preds, waterfall_test_preds) %>%
  mutate(strawman_predicted = Predicted) %>%
  mutate(Actual = case_when(Actual=='sensitive' ~ 1, 
                            Actual=='resistant' ~ 0,
                            Actual=='intermediate' ~ 0.5),
         Predicted = case_when(Predicted=='sensitive' ~ 1, 
                               Predicted=='resistant' ~ 0)) %>%
  bind_rows(probsensitive_test_preds, auc_test_preds) %>%
  left_join(dataset_test %>% select(cell, experiment, auc_recomputed, posterior_probability_sensitive), by=c('cell','experiment'))
```

Bind together all predictions.
```{r}
full.predictions <- all.predictions %>% 
  mutate(dataset = 'insample') %>% 
  bind_rows(all.test.predictions %>% 
              mutate(dataset = 'test'))
```

Join all in-sample diagnostics. 
```{r}
all.diagnostics <- list(naive=naive_diagnostics, 
                        posterior=posterior_diagnostics, 
                        waterfall=waterfall_diagnostics,
                        auc=auc_diagnostics,
                        probsensitive=probsensitive_diagnostics)
all.strawman.diagnostics <- list(naive=naive_strawman,
                        posterior=posterior_strawman, 
                        waterfall=waterfall_strawman,
                        auc=auc_strawman,
                        probsensitive=probsensitive_strawman)
```

Same for test set diagnostics.
```{r}
all.test.diagnostics <- list(naive=naive_test_diagnostics, 
                             posterior=posterior_test_diagnostics, 
                             waterfall=waterfall_test_diagnostics,
                             auc=auc_test_diagnostics,
                             probsensitive=probsensitive_test_diagnostics)
all.test.strawman.diagnostics <- list(naive=naive_test_strawman, 
                                      posterior=posterior_test_strawman, 
                                      waterfall=waterfall_test_strawman,
                                      auc=auc_test_strawman,
                                      probsensitive=probsensitive_test_strawman)
```

Join all continuous diagnostics.
```{r}
continuous.diagnostics <- tibble(Measure = c('posterior_probability_sensitive','auc_recomputed'),
                                 MSE=c(probsensitive_mse,auc_mse),
                                 RSQ=c(probsensitive_rsq,auc_rsq))
continuous.test.diagnostics <- tibble(Measure = c('posterior_probability_sensitive','auc_recomputed'),
                                 MSE=c(probsensitive_test_mse,auc_test_mse),
                                 RSQ=c(probsensitive_test_rsq,auc_test_rsq))
```

Load gene names.
```{r}
ensembl = biomaRt::useEnsembl(biomart="ensembl", dataset="hsapiens_gene_ensembl")
chr_genes <- biomaRt::getBM(attributes=c('ensembl_gene_id','ensembl_transcript_id','hgnc_symbol'), mart = ensembl) %>%
  as_tibble()
all.importance <- all.importance %>%
  separate(feature,into=c('feature','extra1','extra2'), fill='right',sep='_') %>% 
  left_join(chr_genes,by = c('feature'='ensembl_gene_id')) %>%
  mutate(symbol = ifelse(is.na(hgnc_symbol),feature, hgnc_symbol)) %>%
  mutate(type = ifelse(is.na(extra2),extra1, extra2))
```

Plot variable importance.
```{r}
all.importance <- all.importance %>%
  mutate(importance = case_when(is.na(MeanDecreaseGini) ~ IncNodePurity,
                                is.na(IncNodePurity) ~ MeanDecreaseGini)) %>%
  filter(importance>0)

features_to_plot <- all.importance %>% 
  group_by(feature) %>% 
  summarise(total = sum(importance,na.rm=TRUE)) %>%
  ungroup() %>%
  select(total, feature) %>% 
  top_n(min(25,n()), total) %>% 
  pull(feature)

topfeatures_per_model <- all.importance %>% 
  group_by(outcome_variable) %>% 
  top_n(5, importance)
  ungroup() %>%
  pull(feature)

p <- all.importance %>%
  filter(feature %in% c(features_to_plot,topfeatures_per_model)) %>%
  mutate(wt = ifelse(outcome_variable=='posterior_probability_sensitive',1,0)) %>%
  mutate(outcome_variable = case_when(outcome_variable == 'posterior' ~ paste('P(sensitive | AAC) > ',min_posterior_probability_sensitive,sep=''),
                                      outcome_variable == 'naive' ~ paste('AAC > ',naive_cutoff,sep=''),
                                      outcome_variable == 'waterfall' ~ 'Waterfall method',
                                      outcome_variable == 'posterior_probability_sensitive' ~ 'P(sensitive | AAC)',
                                      outcome_variable == 'auc_recomputed' ~ 'AAC')) %>%
  mutate(type = case_when(type == 'mutation' ~ 'Mutation',
                          type == 'rna' ~ 'RNA-seq',
                          type == 'cnv' ~ 'CNV')) %>%
  ggplot(aes(x=reorder(symbol,MeanDecreaseGini*wt), y=importance, color=type, group=symbol)) +
  geom_point() +
  #geom_line(color='grey') +
  theme_bw() + 
  coord_flip() +
  facet_grid(cols=vars(outcome_variable),scales='free_x') + 
  labs(x='Feature',y='Importance',color='Feature type') +
  scale_color_brewer(palette='Dark2') + 
  theme(legend.position='top')
ggsave(file.path(log_dir,'variable_importance.pdf'), p)
saveRDS(p,file.path(log_dir,'variable_importance.RDS'))
```

Print diagnostics.
```{r}
diagnostics <- lapply(1:length(all.diagnostics), function(jj) {
  print(names(all.diagnostics)[jj])
  print(all.diagnostics[[jj]]$table)
  data.frame(Value=all.diagnostics[[jj]]$byClass) %>% 
    rownames_to_column('Metric') %>%
    mutate(Outcome=names(all.diagnostics)[jj]) 
})
diagnostics <- do.call(bind_rows, diagnostics)
```

Print test set diagnostics.
```{r}
test.diagnostics <- lapply(1:length(all.test.diagnostics), function(jj) {
  print(names(all.test.diagnostics)[jj])
  print(all.test.diagnostics[[jj]]$table)
  data.frame(Value=all.test.diagnostics[[jj]]$byClass) %>% 
    rownames_to_column('Metric') %>%
    mutate(Outcome=names(all.test.diagnostics)[jj]) 
})
test.diagnostics <- do.call(bind_rows, test.diagnostics)
```

Print strawman diagnostics.
```{r}
strawman.diagnostics <- lapply(1:length(all.strawman.diagnostics), function(jj) {
  print(names(all.strawman.diagnostics)[jj])
  print(all.strawman.diagnostics[[jj]]$table)
  data.frame(Value=all.strawman.diagnostics[[jj]]$byClass) %>% 
    rownames_to_column('Metric') %>%
    mutate(Outcome=names(all.strawman.diagnostics)[jj]) 
})
strawman.diagnostics <- do.call(bind_rows, strawman.diagnostics)
```

Print test set strawman diagnostics.
```{r}
strawman.test.diagnostics <- lapply(1:length(all.test.strawman.diagnostics), function(jj) {
  print(names(all.test.strawman.diagnostics)[jj])
  print(all.test.strawman.diagnostics[[jj]]$table)
  data.frame(Value=all.test.strawman.diagnostics[[jj]]$byClass) %>% 
    rownames_to_column('Metric') %>%
    mutate(Outcome=names(all.test.strawman.diagnostics)[jj]) 
})
strawman.test.diagnostics <- do.call(bind_rows, strawman.test.diagnostics)
```

Plot in-sample diagnostics.
```{r}
p <- diagnostics %>% 
  ggplot(aes(x=Outcome, y=Value, fill=Outcome)) + 
  geom_bar(stat="identity") + 
  facet_wrap(vars(Metric), ncol=3) +
  theme_bw() + 
  scale_fill_brewer(palette='Dark2') + 
  theme(legend.position='top') + 
  labs(y='', x='', fill='', title='Best Model Fit Diagnostics by Outcome Measure')
ggsave(file.path(log_dir,'diagnostics.pdf'), p)
saveRDS(p,file.path(log_dir,'diagnostics.RDS'))
```

Plot test set diagnostics.
```{r}
p <- test.diagnostics %>% 
  ggplot(aes(x=Outcome, y=Value, fill=Outcome)) + 
  geom_bar(stat="identity") + 
  facet_wrap(vars(Metric), ncol=3) +
  theme_bw() + 
  scale_fill_brewer(palette='Dark2') + 
  theme(legend.position='top') + 
  labs(y='', x='', fill='', title='Best Model Fit Diagnostics by Outcome Measure')
ggsave(file.path(log_dir,'test_diagnostics.pdf'), p)
saveRDS(p,file.path(log_dir,'test_diagnostics.RDS'))
```

Plot in-sample strawman diagnostics.
```{r}
p <- strawman.diagnostics %>% 
  ggplot(aes(x=Outcome, y=Value, fill=Outcome)) + 
  geom_bar(stat="identity") + 
  facet_wrap(vars(Metric), ncol=3) +
  theme_bw() + 
  scale_fill_brewer(palette='Dark2') + 
  theme(legend.position='top') + 
  labs(y='', x='', fill='', title='Best Model Fit Diagnostics by Outcome Measure')
ggsave(file.path(log_dir,'strawman_diagnostics.pdf'), p)
saveRDS(p,file.path(log_dir,'strawman_diagnostics.RDS'))
```

Plot test set strawman diagnostics.
```{r}
p <- strawman.test.diagnostics %>% 
  ggplot(aes(x=Outcome, y=Value, fill=Outcome)) + 
  geom_bar(stat="identity") + 
  facet_wrap(vars(Metric), ncol=3) +
  theme_bw() + 
  scale_fill_brewer(palette='Dark2') + 
  theme(legend.position='top') + 
  labs(y='', x='', fill='', title='Best Model Fit Diagnostics by Outcome Measure')
ggsave(file.path(log_dir,'strawman_test_diagnostics.pdf'), p)
saveRDS(p,file.path(log_dir,'strawman_test_diagnostics.RDS'))
```

Plot continuous diagnostics.
```{r}
p <- continuous.diagnostics %>% 
  mutate(dataset='in sample') %>%
  bind_rows(continuous.test.diagnostics %>% 
              mutate(dataset='test set')) %>%
  gather(quantity, value, -dataset, -Measure) %>%
  ggplot(aes(x=Measure, y=value, fill=Measure)) + 
  geom_bar(stat="identity") + 
  facet_grid(rows=vars(quantity), cols=vars(dataset),scales='free') +
  theme_bw() + 
  scale_fill_brewer(palette='Dark2') + 
  theme(legend.position='top') + 
  labs(y='', x='', fill='', title='Best Model Fit Diagnostics by Outcome Measure')
ggsave(file.path(log_dir,'strawman_test_diagnostics.pdf'), p)
saveRDS(p,file.path(log_dir,'strawman_test_diagnostics.RDS'))
```

Plot predicted versus actual for binary measures.
```{r}
waterfall_vline <- full.predictions %>% 
  filter(Outcome == 'waterfall') %>%
  mutate(Actual = as.factor(Actual)) %>%
  group_by(Actual) %>%
  mutate(maxxx = max(auc_recomputed),
         minnn = min(auc_recomputed)) %>%
  ungroup() %>%
  mutate(meee = case_when(Actual == '0' ~ maxxx, TRUE ~ minnn)) %>%
  filter((Actual == '0' & auc_recomputed == meee) | (Actual == '1' & auc_recomputed == meee)) %>% 
  summarise(meannn = mean(auc_recomputed)) %>% 
  pull(meannn)
p <- full.predictions %>%
  filter(Outcome %in% c('naive','waterfall','posterior')) %>%
  mutate(x = case_when(Outcome %in% c('naive','auc_recomputed','waterfall','posterior') ~ auc_recomputed, 
                       Outcome %in% c('posterior_probability_sensitive') ~ posterior_probability_sensitive),
         y = case_when(Outcome %in% c('naive','waterfall','posterior') ~ posterior_probability_sensitive,
                       Outcome %in% c('auc_recomputed','posterior_probability_sensitive') ~ Predicted),
         color = case_when(Outcome %in% c('naive','waterfall','posterior') ~ as.character(Predicted),
                           Outcome %in% c('auc_recomputed','posterior_probability_sensitive') ~ strawman_predicted),
         color = case_when(color == '0' ~ 'resistant', 
                           color == '1' ~ 'sensitive',
                           TRUE ~ color)) %>%
  select(x, y, color, Outcome, cell, dataset) %>%
  mutate(hline = case_when(Outcome == 'posterior' ~ min_posterior_probability_sensitive,
                           Outcome == 'naive' ~ Inf,
                           Outcome == 'waterfall' ~ Inf),
         vline = case_when(Outcome %in% c('posterior','auc_recomputed','naive','posterior_probability_sensitive') ~ naive_cutoff,
                           Outcome == 'waterfall' ~ waterfall_vline),
         Outcome = case_when(Outcome == 'posterior' ~ paste('P(sensitive | AAC) > ',min_posterior_probability_sensitive,sep=''),
                             Outcome == 'naive' ~ paste('AAC > ',naive_cutoff,sep=''),
                             Outcome == 'waterfall' ~ 'Waterfall method',
                             Outcome == 'auc_recomputed' ~ 'AAC',
                             Outcome == 'posterior_probability_sensitive' ~ 'P(sensitive | AAC)')) %>%
  ggplot(aes(x=x,y=y, color=color)) + 
  geom_point(alpha=.6) + 
  geom_hline(aes(yintercept=hline),lty=2) +
  geom_vline(aes(xintercept=vline),lty=2) +
  facet_grid(cols=vars(Outcome), rows=vars(dataset)) +
  theme_bw() + 
  labs(y='P(sensitive | AAC)',x='AAC', color='Predicted Sensitivity') + 
  theme(legend.position='top') + 
  scale_color_brewer(palette='Dark2')
ggsave(file.path(log_dir,'predicted_v_actual_binary.pdf'), p)
saveRDS(p,file.path(log_dir,'predicted_v_actual_binary.RDS'))
```

Plot predicted versus actual for continuous measures.
```{r}
p <- full.predictions %>%
  filter(Outcome %in% c('auc_recomputed','posterior_probability_sensitive')) %>%
  mutate(x = case_when(Outcome %in% c('naive','auc_recomputed','waterfall','posterior') ~ auc_recomputed, 
                       Outcome %in% c('posterior_probability_sensitive') ~ posterior_probability_sensitive),
         y = case_when(Outcome %in% c('naive','waterfall','posterior') ~ posterior_probability_sensitive,
                       Outcome %in% c('auc_recomputed','posterior_probability_sensitive') ~ Predicted),
         color = case_when(Outcome %in% c('naive','waterfall','posterior') ~ as.character(Predicted),
                           Outcome %in% c('auc_recomputed','posterior_probability_sensitive') ~ strawman_predicted),
         color = case_when(color == '0' ~ 'resistant', 
                           color == '1' ~ 'sensitive',
                           TRUE ~ color)) %>%
  select(x, y, color, Outcome, cell, dataset) %>%
  mutate(hline = naive_cutoff,
         Outcome = case_when(Outcome == 'posterior' ~ paste('P(sensitive | AAC) > ',min_posterior_probability_sensitive,sep=''),
                             Outcome == 'naive' ~ paste('AAC > ',naive_cutoff,sep=''),
                             Outcome == 'waterfall' ~ 'Waterfall method',
                             Outcome == 'auc_recomputed' ~ 'AAC',
                             Outcome == 'posterior_probability_sensitive' ~ 'P(sensitive | AAC)')) %>%
  ggplot(aes(x=x,y=y, color=color)) + 
  geom_point(alpha=.6) + 
  geom_hline(aes(yintercept=hline),lty=2) +
  facet_grid(cols=vars(Outcome), rows=vars(dataset)) +
  theme_bw() + 
  labs(y='Predicted',x='Actual', color=paste('Predicted Sensitivity > ',naive_cutoff,sep='')) + 
  theme(legend.position='top') + 
  scale_color_brewer(palette='Dark2')
ggsave(file.path(log_dir,'predicted_v_actual_continuous.pdf'), p)
saveRDS(p,file.path(log_dir,'predicted_v_actual_continuous.RDS'))
```